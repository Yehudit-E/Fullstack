import os
import requests
from flask import Flask, request, jsonify
from dotenv import load_dotenv
from openai import OpenAI
import tempfile
from flask_cors import CORS

# ×˜×•×¢×Ÿ ×ž×©×ª× ×™ ×¡×‘×™×‘×”
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)

app = Flask(__name__)
CORS(app)

def correct_lyrics(text: str) -> str:
    prompt = f"""
    ×”×—×–×¨ ××ª ×”×©×™×¨ ×‘×¦×•×¨×” × ×§×™×™×” ×•×‘×¨×•×¨×”, ×ž×‘×œ×™ ×œ×”×•×¡×™×£ ×˜×§×¡×˜ ×ž×¡×‘×™×¨.
×”×˜×§×¡×˜ ×”×‘× ×”×•× ×ª×ž×œ×•×œ ×©×œ ×©×™×¨ . ×”×•× ×¢×©×•×™ ×œ×”×›×™×œ ×˜×¢×•×™×•×ª ×›×ª×™×‘, ×˜×¢×•×™×•×ª ×ª×—×‘×™×¨ ×•×’× ×ž×™×œ×™× ×œ× ×ª×§×™× ×•×ª ××• ×œ× ×ž×ª××™×ž×•×ª. 
×ª×§×Ÿ ××•×ª×• ×œ×¢×‘×¨×™×ª ×ª×§× ×™×ª, ×–×•×¨×ž×ª, ×•×ž×“×•×™×§×ª â€” ×›×•×œ×œ ×ª×™×§×•×Ÿ ×ž×™×œ×™× ×©×’×•×™×•×ª ××• ×œ× ×ª×§×™× ×•×ª.
×©×ž×•×¨ ×¢×œ ×”×ž×©×§×œ, ×”×¨×’×© ×•×”×ž×©×ž×¢×•×ª ×©×œ ×”×©×™×¨. ××œ ×ª×•×¡×™×£ ×ž×™×œ×™× ×—×“×©×•×ª ×•××œ ×ª×•×¨×™×“ ×©×•×¨×•×ª ×©×œ×ž×•×ª.
×•×‘× ×•×¡×£ - 

×× × ×‘×¦×¢ ××ª ×”×¤×¢×•×œ×•×ª ×”×‘××•×ª:
1. ×—×œ×§ ××ª ×”×˜×§×¡×˜ ×œ×©×•×¨×•×ª ×©×™×¨ ×‘×¨×•×¨×•×ª â€“ ×›×œ ×©×•×¨×” ×‘×©×•×¨×” ×—×“×©×”.
2. ×—×œ×§ ××ª ×”×©×•×¨×•×ª ×œ×‘×ª×™× â€“ ×›×œ ×‘×™×ª ×ž×•×¤×¨×“ ×¢×œ ×™×“×™ ×©×•×¨×” ×¨×™×§×”.
3. ×ª×§×Ÿ ××ª ×”×˜×¢×•×™×•×ª ×‘×©×™×¨ ×›×š ×©×™×”×™×” ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×ª×§× ×™×ª ×•×–×•×¨×ž×ª, ××š ×©×ž×•×¨ ×¢×œ ×”×ž×©×§×œ, ×”×¨×’×© ×•×”×ž×©×ž×¢×•×ª ×©×œ ×”×©×™×¨.
4. ××œ ×ª×•×¡×™×£ ×©×•×¨×•×ª ××• ×ž×™×œ×™× ×—×“×©×•×ª, ×•××œ ×ª×¡×™×¨ ×©×•×¨×•×ª ×©×œ×ž×•×ª.


---
{text}
---
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "××ª×” ×¢×•×¨×š ×©×™×¨×™× ×‘×¢×‘×¨×™×ª ×‘××•×¤×Ÿ ×©×ž×›×‘×“ ××ª ×”×ž×§×¦×‘, ×”×¨×’×© ×•×”×ž×©×ž×¢×•×ª."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.4,
        max_tokens=1000
    )

    return response.choices[0].message.content


def transcribe_with_whisper(audio_url: str) -> str:
    # ×”×•×¨×“×ª ×§×•×‘×¥ ×–×ž× ×™×ª
    audio_data = requests.get(audio_url)
    audio_data.raise_for_status()

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_audio:
        temp_audio.write(audio_data.content)
        temp_audio_path = temp_audio.name

    # ×©×œ×™×—×ª ×”×§×•×‘×¥ ×œÖ¾Whisper API
    with open(temp_audio_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="he"
        )
    
    os.remove(temp_audio_path)  # × ×™×§×•×™ ×§×•×‘×¥ ×–×ž× ×™

    return correct_lyrics(transcript.text)

@app.route("/")
def index():
    return "×”×©×¨×ª ×¤×•×¢×œ! ðŸŽµ"

@app.route('/transcribe', methods=['POST'])
def handle_transcription():
    data = request.get_json()
    audio_url = data.get('url')
    if not audio_url:
        return jsonify({'error': 'Missing audio URL'}), 400

    try:
        corrected_text = transcribe_with_whisper(audio_url)
        return jsonify({'corrected_lyrics': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    app.run(debug=True)
